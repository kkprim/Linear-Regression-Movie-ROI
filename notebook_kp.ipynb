{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from numbers import Number\n",
    "import sqlite3\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Unzip the .db.zip file\n",
    "with zipfile.ZipFile('zippedData/im.db.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('temp_folder')  \n",
    "    # Extract the database to a temporary folder\n",
    "\n",
    "# 2. Connect to the SQLite database\n",
    "db_file = 'temp_folder/im.db'  \n",
    "# 3. Path to the extracted SQLite database\n",
    "conn = sqlite3.connect(db_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie_basics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>directors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>known_for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie_akas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie_ratings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>persons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>principals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>writers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name\n",
       "0   movie_basics\n",
       "1      directors\n",
       "2      known_for\n",
       "3     movie_akas\n",
       "4  movie_ratings\n",
       "5        persons\n",
       "6     principals\n",
       "7        writers"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query to fetch table information from the schema\n",
    "pd.read_sql('''SELECT name FROM sqlite_master WHERE type='table';''', conn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gross = pd.read_csv('zippedData/bom.movie_gross.csv.gz')\n",
    "df_info = pd.read_csv('zippedData/rt.movie_info.tsv.gz', sep='\\t', encoding='latin')\n",
    "df_reviews = pd.read_csv('zippedData/rt.reviews.tsv.gz', sep='\\t', encoding='latin')\n",
    "df_tmdb = pd.read_csv('zippedData/tmdb.movies.csv.gz')\n",
    "df_budgets = pd.read_csv('zippedData/tn.movie_budgets.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3387 entries, 0 to 3386\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title           3387 non-null   object \n",
      " 1   studio          3382 non-null   object \n",
      " 2   domestic_gross  3359 non-null   float64\n",
      " 3   foreign_gross   2037 non-null   object \n",
      " 4   year            3387 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 132.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_gross.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5782 entries, 0 to 5781\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 5782 non-null   int64 \n",
      " 1   release_date       5782 non-null   object\n",
      " 2   movie              5782 non-null   object\n",
      " 3   production_budget  5782 non-null   object\n",
      " 4   domestic_gross     5782 non-null   object\n",
      " 5   worldwide_gross    5782 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 271.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_budgets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54432 entries, 0 to 54431\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          54432 non-null  int64 \n",
      " 1   review      48869 non-null  object\n",
      " 2   rating      40915 non-null  object\n",
      " 3   fresh       54432 non-null  object\n",
      " 4   critic      51710 non-null  object\n",
      " 5   top_critic  54432 non-null  int64 \n",
      " 6   publisher   54123 non-null  object\n",
      " 7   date        54432 non-null  object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>studio</th>\n",
       "      <th>domestic_gross</th>\n",
       "      <th>foreign_gross</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>BV</td>\n",
       "      <td>415000000.0</td>\n",
       "      <td>652000000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice in Wonderland (2010)</td>\n",
       "      <td>BV</td>\n",
       "      <td>334200000.0</td>\n",
       "      <td>691300000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Deathly Hallows Part 1</td>\n",
       "      <td>WB</td>\n",
       "      <td>296000000.0</td>\n",
       "      <td>664300000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inception</td>\n",
       "      <td>WB</td>\n",
       "      <td>292600000.0</td>\n",
       "      <td>535700000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shrek Forever After</td>\n",
       "      <td>P/DW</td>\n",
       "      <td>238700000.0</td>\n",
       "      <td>513900000</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title studio  domestic_gross  \\\n",
       "0                                  Toy Story 3     BV     415000000.0   \n",
       "1                   Alice in Wonderland (2010)     BV     334200000.0   \n",
       "2  Harry Potter and the Deathly Hallows Part 1     WB     296000000.0   \n",
       "3                                    Inception     WB     292600000.0   \n",
       "4                          Shrek Forever After   P/DW     238700000.0   \n",
       "\n",
       "  foreign_gross  year  \n",
       "0     652000000  2010  \n",
       "1     691300000  2010  \n",
       "2     664300000  2010  \n",
       "3     535700000  2010  \n",
       "4     513900000  2010  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gross.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie</th>\n",
       "      <th>production_budget</th>\n",
       "      <th>domestic_gross</th>\n",
       "      <th>worldwide_gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dec 18, 2009</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>$425,000,000</td>\n",
       "      <td>$760,507,625</td>\n",
       "      <td>$2,776,345,279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>May 20, 2011</td>\n",
       "      <td>Pirates of the Caribbean: On Stranger Tides</td>\n",
       "      <td>$410,600,000</td>\n",
       "      <td>$241,063,875</td>\n",
       "      <td>$1,045,663,875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jun 7, 2019</td>\n",
       "      <td>Dark Phoenix</td>\n",
       "      <td>$350,000,000</td>\n",
       "      <td>$42,762,350</td>\n",
       "      <td>$149,762,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>May 1, 2015</td>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>$330,600,000</td>\n",
       "      <td>$459,005,868</td>\n",
       "      <td>$1,403,013,963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Dec 15, 2017</td>\n",
       "      <td>Star Wars Ep. VIII: The Last Jedi</td>\n",
       "      <td>$317,000,000</td>\n",
       "      <td>$620,181,382</td>\n",
       "      <td>$1,316,721,747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  release_date                                        movie  \\\n",
       "0   1  Dec 18, 2009                                       Avatar   \n",
       "1   2  May 20, 2011  Pirates of the Caribbean: On Stranger Tides   \n",
       "2   3   Jun 7, 2019                                 Dark Phoenix   \n",
       "3   4   May 1, 2015                      Avengers: Age of Ultron   \n",
       "4   5  Dec 15, 2017            Star Wars Ep. VIII: The Last Jedi   \n",
       "\n",
       "  production_budget domestic_gross worldwide_gross  \n",
       "0      $425,000,000   $760,507,625  $2,776,345,279  \n",
       "1      $410,600,000   $241,063,875  $1,045,663,875  \n",
       "2      $350,000,000    $42,762,350    $149,762,350  \n",
       "3      $330,600,000   $459,005,868  $1,403,013,963  \n",
       "4      $317,000,000   $620,181,382  $1,316,721,747  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_budgets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>fresh</th>\n",
       "      <th>critic</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A distinctly gallows take on contemporary fina...</td>\n",
       "      <td>3/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>PJ Nabarro</td>\n",
       "      <td>0</td>\n",
       "      <td>Patrick Nabarro</td>\n",
       "      <td>November 10, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>It's an allegory in search of a meaning that n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotten</td>\n",
       "      <td>Annalee Newitz</td>\n",
       "      <td>0</td>\n",
       "      <td>io9.com</td>\n",
       "      <td>May 23, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>... life lived in a bubble in financial dealin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Sean Axmaker</td>\n",
       "      <td>0</td>\n",
       "      <td>Stream on Demand</td>\n",
       "      <td>January 4, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Continuing along a line introduced in last yea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Daniel Kasman</td>\n",
       "      <td>0</td>\n",
       "      <td>MUBI</td>\n",
       "      <td>November 16, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>... a perverse twist on neorealism...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Cinema Scope</td>\n",
       "      <td>October 12, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review rating   fresh  \\\n",
       "0   3  A distinctly gallows take on contemporary fina...    3/5   fresh   \n",
       "1   3  It's an allegory in search of a meaning that n...    NaN  rotten   \n",
       "2   3  ... life lived in a bubble in financial dealin...    NaN   fresh   \n",
       "3   3  Continuing along a line introduced in last yea...    NaN   fresh   \n",
       "4   3             ... a perverse twist on neorealism...     NaN   fresh   \n",
       "\n",
       "           critic  top_critic         publisher               date  \n",
       "0      PJ Nabarro           0   Patrick Nabarro  November 10, 2018  \n",
       "1  Annalee Newitz           0           io9.com       May 23, 2018  \n",
       "2    Sean Axmaker           0  Stream on Demand    January 4, 2018  \n",
       "3   Daniel Kasman           0              MUBI  November 16, 2017  \n",
       "4             NaN           0      Cinema Scope   October 12, 2017  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>primary_title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>start_year</th>\n",
       "      <th>runtime_minutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>averagerating</th>\n",
       "      <th>numvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0063540</td>\n",
       "      <td>Sunghursh</td>\n",
       "      <td>Sunghursh</td>\n",
       "      <td>2013</td>\n",
       "      <td>175.0</td>\n",
       "      <td>Action,Crime,Drama</td>\n",
       "      <td>tt0063540</td>\n",
       "      <td>7.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0066787</td>\n",
       "      <td>One Day Before the Rainy Season</td>\n",
       "      <td>Ashad Ka Ek Din</td>\n",
       "      <td>2019</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Biography,Drama</td>\n",
       "      <td>tt0066787</td>\n",
       "      <td>7.2</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0069049</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>2018</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>tt0069049</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0069204</td>\n",
       "      <td>Sabse Bada Sukh</td>\n",
       "      <td>Sabse Bada Sukh</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy,Drama</td>\n",
       "      <td>tt0069204</td>\n",
       "      <td>6.1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0100275</td>\n",
       "      <td>The Wandering Soap Opera</td>\n",
       "      <td>La Telenovela Errante</td>\n",
       "      <td>2017</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Comedy,Drama,Fantasy</td>\n",
       "      <td>tt0100275</td>\n",
       "      <td>6.5</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt0112502</td>\n",
       "      <td>Bigfoot</td>\n",
       "      <td>Bigfoot</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Horror,Thriller</td>\n",
       "      <td>tt0112502</td>\n",
       "      <td>4.1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tt0137204</td>\n",
       "      <td>Joe Finds Grace</td>\n",
       "      <td>Joe Finds Grace</td>\n",
       "      <td>2017</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Adventure,Animation,Comedy</td>\n",
       "      <td>tt0137204</td>\n",
       "      <td>8.1</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tt0146592</td>\n",
       "      <td>Pál Adrienn</td>\n",
       "      <td>Pál Adrienn</td>\n",
       "      <td>2010</td>\n",
       "      <td>136.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>tt0146592</td>\n",
       "      <td>6.8</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tt0154039</td>\n",
       "      <td>So Much for Justice!</td>\n",
       "      <td>Oda az igazság</td>\n",
       "      <td>2010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>History</td>\n",
       "      <td>tt0154039</td>\n",
       "      <td>4.6</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tt0159369</td>\n",
       "      <td>Cooper and Hemingway: The True Gen</td>\n",
       "      <td>Cooper and Hemingway: The True Gen</td>\n",
       "      <td>2013</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>tt0159369</td>\n",
       "      <td>7.6</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id                       primary_title  \\\n",
       "0  tt0063540                           Sunghursh   \n",
       "1  tt0066787     One Day Before the Rainy Season   \n",
       "2  tt0069049          The Other Side of the Wind   \n",
       "3  tt0069204                     Sabse Bada Sukh   \n",
       "4  tt0100275            The Wandering Soap Opera   \n",
       "5  tt0112502                             Bigfoot   \n",
       "6  tt0137204                     Joe Finds Grace   \n",
       "7  tt0146592                         Pál Adrienn   \n",
       "8  tt0154039                So Much for Justice!   \n",
       "9  tt0159369  Cooper and Hemingway: The True Gen   \n",
       "\n",
       "                       original_title  start_year  runtime_minutes  \\\n",
       "0                           Sunghursh        2013            175.0   \n",
       "1                     Ashad Ka Ek Din        2019            114.0   \n",
       "2          The Other Side of the Wind        2018            122.0   \n",
       "3                     Sabse Bada Sukh        2018              NaN   \n",
       "4               La Telenovela Errante        2017             80.0   \n",
       "5                             Bigfoot        2017              NaN   \n",
       "6                     Joe Finds Grace        2017             83.0   \n",
       "7                         Pál Adrienn        2010            136.0   \n",
       "8                      Oda az igazság        2010            100.0   \n",
       "9  Cooper and Hemingway: The True Gen        2013            180.0   \n",
       "\n",
       "                       genres   movie_id  averagerating  numvotes  \n",
       "0          Action,Crime,Drama  tt0063540            7.0        77  \n",
       "1             Biography,Drama  tt0066787            7.2        43  \n",
       "2                       Drama  tt0069049            6.9      4517  \n",
       "3                Comedy,Drama  tt0069204            6.1        13  \n",
       "4        Comedy,Drama,Fantasy  tt0100275            6.5       119  \n",
       "5             Horror,Thriller  tt0112502            4.1        32  \n",
       "6  Adventure,Animation,Comedy  tt0137204            8.1       263  \n",
       "7                       Drama  tt0146592            6.8       451  \n",
       "8                     History  tt0154039            4.6        64  \n",
       "9                 Documentary  tt0159369            7.6        53  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('''\n",
    "    SELECT *\n",
    "    FROM movie_basics as mb\n",
    "    INNER JOIN movie_ratings as mr\n",
    "    ON mb.movie_id = mr.movie_id\n",
    "    LIMIT 10;''', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146144 entries, 0 to 146143\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   movie_id         146144 non-null  object \n",
      " 1   primary_title    146144 non-null  object \n",
      " 2   original_title   146123 non-null  object \n",
      " 3   start_year       146144 non-null  int64  \n",
      " 4   runtime_minutes  114405 non-null  float64\n",
      " 5   genres           140736 non-null  object \n",
      " 6   movie_id         73856 non-null   object \n",
      " 7   averagerating    73856 non-null   float64\n",
      " 8   numvotes         73856 non-null   float64\n",
      "dtypes: float64(3), int64(1), object(5)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "basics_ratings = pd.read_sql('''\n",
    "    SELECT *\n",
    "    FROM movie_basics as mb\n",
    "    LEFT JOIN movie_ratings as mr\n",
    "    ON mb.movie_id = mr.movie_id;''', conn).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 146146 entries, 0 to 146145\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   movie_id         146146 non-null  object \n",
      " 1   primary_title    146146 non-null  object \n",
      " 2   original_title   146125 non-null  object \n",
      " 3   start_year       146146 non-null  int64  \n",
      " 4   runtime_minutes  114407 non-null  float64\n",
      " 5   genres           140738 non-null  object \n",
      " 6   movie_id         73858 non-null   object \n",
      " 7   averagerating    73858 non-null   float64\n",
      " 8   numvotes         73858 non-null   float64\n",
      " 9   title            3366 non-null    object \n",
      " 10  studio           3363 non-null    object \n",
      " 11  domestic_gross   3342 non-null    float64\n",
      " 12  foreign_gross    2043 non-null    object \n",
      " 13  year             3366 non-null    float64\n",
      "dtypes: float64(5), int64(1), object(8)\n",
      "memory usage: 16.7+ MB\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Step 1: Load data from SQL table into a Pandas DataFrame\n",
    "engine = create_engine('sqlite:///temp_folder/im.db')  \n",
    "sql_query = 'SELECT * FROM movie_basics as mb LEFT JOIN movie_ratings as mr ON mb.movie_id = mr.movie_id'\n",
    "df_sql = pd.read_sql(sql_query, engine)\n",
    "\n",
    "# Step 3: Combine data with different column names\n",
    "# Specify the column names explicitly using left_on and right_on parameters\n",
    "result_df_left = pd.merge(df_sql, df_gross, left_on='primary_title', right_on='title', how='left')\n",
    "result_df_left.info()\n",
    "result_df_left.to_csv('result_left.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3366 entries, 0 to 3365\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   movie_id         3366 non-null   object \n",
      " 1   primary_title    3366 non-null   object \n",
      " 2   original_title   3366 non-null   object \n",
      " 3   start_year       3366 non-null   int64  \n",
      " 4   runtime_minutes  3198 non-null   float64\n",
      " 5   genres           3326 non-null   object \n",
      " 6   movie_id         3027 non-null   object \n",
      " 7   averagerating    3027 non-null   float64\n",
      " 8   numvotes         3027 non-null   float64\n",
      " 9   title            3366 non-null   object \n",
      " 10  studio           3363 non-null   object \n",
      " 11  domestic_gross   3342 non-null   float64\n",
      " 12  foreign_gross    2043 non-null   object \n",
      " 13  year             3366 non-null   int64  \n",
      "dtypes: float64(4), int64(2), object(8)\n",
      "memory usage: 394.5+ KB\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Step 1: Load data from SQL table into a Pandas DataFrame\n",
    "engine = create_engine('sqlite:///temp_folder/im.db')  # Replace with your database connection details\n",
    "sql_query = 'SELECT * FROM movie_basics as mb LEFT JOIN movie_ratings as mr ON mb.movie_id = mr.movie_id'\n",
    "df_sql = pd.read_sql(sql_query, engine)\n",
    "\n",
    "# Step 3: Combine data with different column names\n",
    "# Specify the column names explicitly using left_on and right_on parameters\n",
    "result_df_inner = pd.merge(df_sql, df_gross, left_on='primary_title', right_on='title', how='inner')\n",
    "result_df_inner.info()\n",
    "result_df_inner.to_csv('result_inner.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                   Release Group       Worldwide      Domestic  \\\n",
      "0       1                          Barbie  $1,440,380,000  $635,680,000   \n",
      "1       2     The Super Mario Bros. Movie  $1,362,659,200  $574,934,330   \n",
      "2       3                     Oppenheimer    $945,362,510  $324,042,510   \n",
      "3       4  Guardians of the Galaxy Vol. 3    $845,555,777  $358,995,815   \n",
      "4       5                          Fast X    $704,709,660  $145,960,660   \n",
      "..    ...                             ...             ...           ...   \n",
      "195   196                            2018      $4,547,765             -   \n",
      "196   197               IM HERO THE FINAL      $4,514,656             -   \n",
      "197   198                       Mari(dos)      $4,483,495             -   \n",
      "198   199                  Weekend Rebels      $4,477,262             -   \n",
      "199   200                       Maamannan      $4,463,992             -   \n",
      "\n",
      "         %       Foreign    %.1  \n",
      "0    44.1%  $804,700,000  55.9%  \n",
      "1    42.2%  $787,724,870  57.8%  \n",
      "2    34.3%  $621,320,000  65.7%  \n",
      "3    42.5%  $486,559,962  57.5%  \n",
      "4    20.7%  $558,749,000  79.3%  \n",
      "..     ...           ...    ...  \n",
      "195      -    $4,547,765   100%  \n",
      "196      -    $4,514,656   100%  \n",
      "197      -    $4,483,495   100%  \n",
      "198      -    $4,477,262   100%  \n",
      "199      -    $4,463,992   100%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2023/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2023 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2023)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                                Release Group       Worldwide  \\\n",
      "0       1                     Avatar: The Way of Water  $2,320,250,281   \n",
      "1       2                            Top Gun: Maverick  $1,495,696,292   \n",
      "2       3                      Jurassic World Dominion  $1,001,978,080   \n",
      "3       4  Doctor Strange in the Multiverse of Madness    $955,775,804   \n",
      "4       5                     Minions: The Rise of Gru    $939,628,210   \n",
      "..    ...                                          ...             ...   \n",
      "195   196                             Lesson in Murder      $7,348,964   \n",
      "196   197                               Family Affairs      $7,330,755   \n",
      "197   198                                Listy do M. 5      $7,328,061   \n",
      "198   199                         Laid-Back Camp Movie      $7,317,913   \n",
      "199   200        Osomatsusan the Movie 2022 Re-release      $7,297,522   \n",
      "\n",
      "         Domestic      %         Foreign    %.1  \n",
      "0    $684,075,767  29.5%  $1,636,174,514  70.5%  \n",
      "1    $718,732,821  48.1%    $776,963,471  51.9%  \n",
      "2    $376,851,080  37.6%    $625,127,000  62.4%  \n",
      "3    $411,331,607    43%    $544,444,197    57%  \n",
      "4    $369,695,210  39.3%    $569,933,000  60.7%  \n",
      "..            ...    ...             ...    ...  \n",
      "195             -      -      $7,348,964   100%  \n",
      "196             -      -      $7,330,755   100%  \n",
      "197             -      -      $7,328,061   100%  \n",
      "198             -      -      $7,317,913   100%  \n",
      "199             -      -      $7,297,522   100%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2022/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2022 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2022)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                Release Group       Worldwide      Domestic      %  \\\n",
      "0       1      Spider-Man: No Way Home  $1,912,233,593  $804,793,477  42.1%   \n",
      "1       2  The Battle at Lake Changjin    $902,548,476      $342,411  <0.1%   \n",
      "2       3                      Hi, Mom    $822,009,764             -      -   \n",
      "3       4               No Time to Die    $774,153,007  $160,891,007  20.8%   \n",
      "4       5            F9: The Fast Saga    $726,229,501  $173,005,945  23.8%   \n",
      "..    ...                          ...             ...           ...    ...   \n",
      "195   196              The Mauritanian      $7,527,030      $836,536  11.1%   \n",
      "196   197                 The Ice Road      $7,502,846             -      -   \n",
      "197   198  Judas and the Black Messiah      $7,478,009    $5,478,009  73.3%   \n",
      "198   199  Love Letter 2021 Re-release      $7,400,000             -      -   \n",
      "199   200            Signal: The Movie      $7,388,603             -      -   \n",
      "\n",
      "            Foreign    %.1  \n",
      "0    $1,107,440,116  57.9%  \n",
      "1      $902,206,065   100%  \n",
      "2      $822,009,764   100%  \n",
      "3      $613,262,000  79.2%  \n",
      "4      $553,223,556  76.2%  \n",
      "..              ...    ...  \n",
      "195      $6,690,494  88.9%  \n",
      "196      $7,502,846   100%  \n",
      "197      $2,000,000  26.7%  \n",
      "198      $7,400,000   100%  \n",
      "199      $7,388,603   100%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2021/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2021 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2021)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                                      Release Group     Worldwide  \\\n",
      "0       1                                  The Eight Hundred  $461,421,559   \n",
      "1       2  Demon Slayer: Kimetsu no Yaiba - The Movie: Mu...  $453,210,959   \n",
      "2       3                                  Bad Boys for Life  $426,505,244   \n",
      "3       4                             My People, My Homeland  $422,390,820   \n",
      "4       5                                              Tenet  $365,304,105   \n",
      "..    ...                                                ...           ...   \n",
      "195   196                                              Panga    $4,886,124   \n",
      "196   197                        The Tales for Old and Young    $4,853,143   \n",
      "197   198                                          Streltsov    $4,850,073   \n",
      "198   199                                    Persian Lessons    $4,849,240   \n",
      "199   200             The SpongeBob Movie: Sponge on the Run    $4,810,790   \n",
      "\n",
      "         Domestic      %       Foreign    %.1  \n",
      "0        $372,755  <0.1%  $461,048,804  99.9%  \n",
      "1     $49,505,008  10.9%  $403,705,951  89.1%  \n",
      "2    $206,305,244  48.4%  $220,200,000  51.6%  \n",
      "3               -      -  $422,390,820   100%  \n",
      "4     $58,504,105    16%  $306,800,000    84%  \n",
      "..            ...    ...           ...    ...  \n",
      "195      $582,720  11.9%    $4,303,404  88.1%  \n",
      "196             -      -    $4,853,143   100%  \n",
      "197             -      -    $4,850,073   100%  \n",
      "198             -      -    $4,849,240   100%  \n",
      "199    $4,810,790   100%             -      -  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2020/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2020 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2020)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                                      Release Group       Worldwide  \\\n",
      "0       1                                  Avengers: Endgame  $2,799,439,100   \n",
      "1       2                                      The Lion King  $1,656,943,394   \n",
      "2       3                                          Frozen II  $1,450,026,933   \n",
      "3       4                          Spider-Man: Far from Home  $1,131,927,996   \n",
      "4       5                                     Captain Marvel  $1,128,274,794   \n",
      "..    ...                                                ...             ...   \n",
      "195   196                                       The Specials     $19,363,826   \n",
      "196   197                                    Always Miss You     $19,015,465   \n",
      "197   198                               An Officer and a Spy     $18,899,214   \n",
      "198   199  Crayon Shin-chan: Honeymoon Hurricane - The Lo...     $18,738,951   \n",
      "199   200                                              Greta     $18,653,107   \n",
      "\n",
      "         Domestic      %         Foreign    %.1  \n",
      "0    $858,373,000  30.7%  $1,941,066,100  69.3%  \n",
      "1    $543,638,043  32.8%  $1,113,305,351  67.2%  \n",
      "2    $477,373,578  32.9%    $972,653,355  67.1%  \n",
      "3    $390,532,085  34.5%    $741,395,911  65.5%  \n",
      "4    $426,829,839  37.8%    $701,444,955  62.2%  \n",
      "..            ...    ...             ...    ...  \n",
      "195             -      -     $19,363,826   100%  \n",
      "196       $91,884   0.5%     $18,923,581  99.5%  \n",
      "197             -      -     $18,899,214   100%  \n",
      "198             -      -     $18,738,951   100%  \n",
      "199   $10,532,219  56.5%      $8,120,888  43.5%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2019/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2019 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2019)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                   Release Group       Worldwide      Domestic  \\\n",
      "0       1          Avengers: Infinity War  $2,048,359,754  $678,815,482   \n",
      "1       2                   Black Panther  $1,346,913,161  $700,059,566   \n",
      "2       3  Jurassic World: Fallen Kingdom  $1,308,467,944  $417,719,760   \n",
      "3       4                   Incredibles 2  $1,242,805,359  $608,581,744   \n",
      "4       5                         Aquaman  $1,151,961,807  $335,061,807   \n",
      "..    ...                             ...             ...           ...   \n",
      "195   196                       Padmaavat     $22,991,060   $11,846,060   \n",
      "196   197       Won't You Be My Neighbor?     $22,844,741   $22,835,787   \n",
      "197   198                  Europe Raiders     $22,435,156             -   \n",
      "198   199          Mojin: The Worm Valley     $22,381,583      $101,516   \n",
      "199   200                           Stree     $22,075,730             -   \n",
      "\n",
      "         %         Foreign    %.1  \n",
      "0    33.1%  $1,369,544,272  66.9%  \n",
      "1      52%    $646,853,595    48%  \n",
      "2    31.9%    $890,748,184  68.1%  \n",
      "3      49%    $634,223,615    51%  \n",
      "4    29.1%    $816,900,000  70.9%  \n",
      "..     ...             ...    ...  \n",
      "195  51.5%     $11,145,000  48.5%  \n",
      "196   100%          $8,954  <0.1%  \n",
      "197      -     $22,435,156   100%  \n",
      "198   0.5%     $22,280,067  99.5%  \n",
      "199      -     $22,075,730   100%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2018/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2018 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2018)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                            Release Group       Worldwide  \\\n",
      "0       1  Star Wars: Episode VIII - The Last Jedi  $1,332,539,889   \n",
      "1       2                     Beauty and the Beast  $1,263,521,126   \n",
      "2       3                  The Fate of the Furious  $1,236,005,118   \n",
      "3       4                          Despicable Me 3  $1,034,799,409   \n",
      "4       5           Jumanji: Welcome to the Jungle    $962,077,546   \n",
      "..    ...                                      ...             ...   \n",
      "195   196                    Extraordinary Mission     $22,757,764   \n",
      "196   197                         The Glass Castle     $22,088,533   \n",
      "197   198                      Épouse-moi mon pote     $21,571,464   \n",
      "198   199                               The Prison     $21,205,329   \n",
      "199   200         One Hundred Thousand Bad Jokes 2     $20,460,352   \n",
      "\n",
      "         Domestic      %         Foreign    %.1  \n",
      "0    $620,181,382  46.5%    $712,358,507  53.5%  \n",
      "1    $504,014,165  39.9%    $759,506,961  60.1%  \n",
      "2    $226,008,385  18.3%  $1,009,996,733  81.7%  \n",
      "3    $264,624,300  25.6%    $770,175,109  74.4%  \n",
      "4    $404,515,480    42%    $557,562,066    58%  \n",
      "..            ...    ...             ...    ...  \n",
      "195       $54,174   0.2%     $22,703,590  99.8%  \n",
      "196   $17,273,059  78.2%      $4,815,474  21.8%  \n",
      "197             -      -     $21,571,464   100%  \n",
      "198      $207,481     1%     $20,997,848    99%  \n",
      "199             -      -     $20,460,352   100%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2017/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2017 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2017)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                              Release Group       Worldwide  \\\n",
      "0       1                 Captain America: Civil War  $1,153,296,293   \n",
      "1       2               Rogue One: A Star Wars Story  $1,056,057,273   \n",
      "2       3                               Finding Dory  $1,028,570,889   \n",
      "3       4                                   Zootopia  $1,023,784,195   \n",
      "4       5                            The Jungle Book    $966,550,600   \n",
      "..    ...                                        ...             ...   \n",
      "195   196  Middle School: The Worst Years of My Life     $23,316,139   \n",
      "196   197                                   Triple 9     $23,177,948   \n",
      "197   198                                   Rock Dog     $23,139,802   \n",
      "198   199                                 The Choice     $23,064,015   \n",
      "199   200                             Penny Pincher!     $22,955,486   \n",
      "\n",
      "         Domestic      %       Foreign    %.1  \n",
      "0    $408,084,349  35.4%  $745,211,944  64.6%  \n",
      "1    $532,177,324  50.4%  $523,879,949  49.6%  \n",
      "2    $486,295,561  47.3%  $542,275,328  52.7%  \n",
      "3    $341,268,248  33.3%  $682,515,947  66.7%  \n",
      "4    $364,001,123  37.7%  $602,549,477  62.3%  \n",
      "..            ...    ...           ...    ...  \n",
      "195   $20,007,149  85.8%    $3,308,990  14.2%  \n",
      "196   $12,639,297  54.5%   $10,538,651  45.5%  \n",
      "197    $9,420,546  40.7%   $13,719,256  59.3%  \n",
      "198   $18,730,891  81.2%    $4,333,124  18.8%  \n",
      "199             -      -   $22,955,486   100%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2016/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2016 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2016)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                                   Release Group       Worldwide  \\\n",
      "0       1      Star Wars: Episode VII - The Force Awakens  $2,068,223,624   \n",
      "1       2                                  Jurassic World  $1,670,400,637   \n",
      "2       3                                       Furious 7  $1,515,047,671   \n",
      "3       4                         Avengers: Age of Ultron  $1,402,805,868   \n",
      "4       5                                         Minions  $1,159,398,397   \n",
      "..    ...                                             ...             ...   \n",
      "195   196  Huevos: Little Rooster's Egg-cellent Adventure     $25,892,561   \n",
      "196   197                          Dügün Dernek 2: Sünnet     $25,836,668   \n",
      "197   198                                 Look Who's Back     $25,513,752   \n",
      "198   199                               Serial Teachers 2     $25,364,150   \n",
      "199   200                                       Wild City     $24,817,852   \n",
      "\n",
      "         Domestic      %         Foreign    %.1  \n",
      "0    $936,662,225  45.3%  $1,131,561,399  54.7%  \n",
      "1    $652,270,625    39%  $1,018,130,012    61%  \n",
      "2    $353,007,020  23.3%  $1,162,040,651  76.7%  \n",
      "3    $459,005,868  32.7%    $943,800,000  67.3%  \n",
      "4    $336,045,770    29%    $823,352,627    71%  \n",
      "..            ...    ...             ...    ...  \n",
      "195    $9,080,818  35.1%     $16,811,743  64.9%  \n",
      "196             -      -     $25,836,668   100%  \n",
      "197             -      -     $25,513,752   100%  \n",
      "198             -      -     $25,364,150   100%  \n",
      "199       $34,866   0.1%     $24,782,986  99.9%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2015/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2015 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2015)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                              Release Group       Worldwide  \\\n",
      "0       1            Transformers: Age of Extinction  $1,104,054,072   \n",
      "1       2  The Hobbit: The Battle of the Five Armies    $956,019,788   \n",
      "2       3                    Guardians of the Galaxy    $772,776,600   \n",
      "3       4                                 Maleficent    $758,410,378   \n",
      "4       5      The Hunger Games: Mockingjay - Part 1    $755,356,711   \n",
      "..    ...                                        ...             ...   \n",
      "195   196                          A Haunted House 2     $25,358,716   \n",
      "196   197                             And So It Goes     $25,312,387   \n",
      "197   198                             Kung Fu Jungle     $24,070,765   \n",
      "198   199                                   Hot Road     $22,916,313   \n",
      "199   200                              Fading Gigolo     $22,706,304   \n",
      "\n",
      "         Domestic      %       Foreign    %.1  \n",
      "0    $245,439,076  22.2%  $858,614,996  77.8%  \n",
      "1    $255,119,788  26.7%  $700,900,000  73.3%  \n",
      "2    $333,176,600  43.1%  $439,600,000  56.9%  \n",
      "3    $241,410,378  31.8%  $517,000,000  68.2%  \n",
      "4    $337,135,885  44.6%  $418,220,826  55.4%  \n",
      "..            ...    ...           ...    ...  \n",
      "195   $17,329,486  68.3%    $8,029,230  31.7%  \n",
      "196   $15,160,801  59.9%   $10,151,586  40.1%  \n",
      "197      $129,784   0.5%   $23,940,981  99.5%  \n",
      "198             -      -   $22,916,313   100%  \n",
      "199    $3,769,873  16.6%   $18,936,431  83.4%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2014/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2014 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2014)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                        Release Group       Worldwide      Domestic  \\\n",
      "0       1                               Frozen  $1,280,802,282  $400,738,009   \n",
      "1       2                           Iron Man 3  $1,214,811,252  $409,013,994   \n",
      "2       3                      Despicable Me 2    $970,766,005  $368,065,385   \n",
      "3       4  The Hobbit: The Desolation of Smaug    $958,366,855  $258,366,855   \n",
      "4       5      The Hunger Games: Catching Fire    $865,011,746  $424,668,047   \n",
      "..    ...                                  ...             ...           ...   \n",
      "195   196                     The Great Beauty     $24,350,615    $2,852,400   \n",
      "196   197                               Trance     $24,261,569    $2,328,743   \n",
      "197   198                      The Railway Man     $24,174,885    $4,438,438   \n",
      "198   199                       Out of Inferno     $24,109,886             -   \n",
      "199   200                 Bring Happiness Home     $23,980,000             -   \n",
      "\n",
      "         %       Foreign    %.1  \n",
      "0    31.3%  $880,064,273  68.7%  \n",
      "1    33.7%  $805,797,258  66.3%  \n",
      "2    37.9%  $602,700,620  62.1%  \n",
      "3      27%  $700,000,000    73%  \n",
      "4    49.1%  $440,343,699  50.9%  \n",
      "..     ...           ...    ...  \n",
      "195  11.7%   $21,498,215  88.3%  \n",
      "196   9.6%   $21,932,826  90.4%  \n",
      "197  18.4%   $19,736,447  81.6%  \n",
      "198      -   $24,109,886   100%  \n",
      "199      -   $23,980,000   100%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2013/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2013 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2013)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                      Release Group       Worldwide      Domestic  \\\n",
      "0       1                       The Avengers  $1,518,812,988  $623,357,910   \n",
      "1       2                            Skyfall  $1,108,561,013  $304,360,277   \n",
      "2       3              The Dark Knight Rises  $1,084,939,099  $448,139,099   \n",
      "3       4  The Hobbit: An Unexpected Journey  $1,017,003,568  $303,003,568   \n",
      "4       5         Ice Age: Continental Drift    $877,244,782  $161,321,843   \n",
      "..    ...                                ...             ...           ...   \n",
      "195   196                            Unbowed     $22,132,903             -   \n",
      "196   197               Confession of Murder     $21,701,525             -   \n",
      "197   198      StreetDance 2 2012 Re-release     $21,638,853             -   \n",
      "198   199               2012 2012 Re-release     $21,538,353             -   \n",
      "199   200        Beasts of the Southern Wild     $21,107,746   $12,795,746   \n",
      "\n",
      "         %       Foreign    %.1  \n",
      "0      41%  $895,455,078    59%  \n",
      "1    27.5%  $804,200,736  72.5%  \n",
      "2    41.3%  $636,800,000  58.7%  \n",
      "3    29.8%  $714,000,000  70.2%  \n",
      "4    18.4%  $715,922,939  81.6%  \n",
      "..     ...           ...    ...  \n",
      "195      -   $22,132,903   100%  \n",
      "196      -   $21,701,525   100%  \n",
      "197      -   $21,638,853   100%  \n",
      "198      -   $21,538,353   100%  \n",
      "199  60.6%    $8,312,000  39.4%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2012/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2012 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2012)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                                 Release Group       Worldwide  \\\n",
      "0       1  Harry Potter and the Deathly Hallows: Part 2  $1,341,511,219   \n",
      "1       2                Transformers: Dark of the Moon  $1,123,794,079   \n",
      "2       3   Pirates of the Caribbean: On Stranger Tides  $1,045,713,802   \n",
      "3       4     The Twilight Saga: Breaking Dawn - Part 1    $712,205,856   \n",
      "4       5          Mission: Impossible - Ghost Protocol    $694,713,380   \n",
      "..    ...                                           ...             ...   \n",
      "195   196                                The Front Line     $20,629,645   \n",
      "196   197                                       Polisse     $20,590,872   \n",
      "197   198                                      Hollywoo     $20,587,850   \n",
      "198   199                              Scabbard Samurai     $20,251,745   \n",
      "199   200                 Kaiji 2: The Ultimate Gambler     $19,971,259   \n",
      "\n",
      "         Domestic      %       Foreign    %.1  \n",
      "0    $381,011,219  28.4%  $960,500,000  71.6%  \n",
      "1    $352,390,543  31.4%  $771,403,536  68.6%  \n",
      "2    $241,071,802  23.1%  $804,642,000  76.9%  \n",
      "3    $281,287,133  39.5%  $430,918,723  60.5%  \n",
      "4    $209,397,903  30.1%  $485,315,477  69.9%  \n",
      "..            ...    ...           ...    ...  \n",
      "195       $11,018  <0.1%   $20,618,627  99.9%  \n",
      "196      $211,440     1%   $20,379,432    99%  \n",
      "197             -      -   $20,587,850   100%  \n",
      "198             -      -   $20,251,745   100%  \n",
      "199             -      -   $19,971,259   100%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2011/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2011 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2011)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank                                 Release Group       Worldwide  \\\n",
      "0       1                                   Toy Story 3  $1,066,969,703   \n",
      "1       2                           Alice in Wonderland  $1,025,467,110   \n",
      "2       3  Harry Potter and the Deathly Hallows: Part 1    $976,536,918   \n",
      "3       4                                     Inception    $828,258,695   \n",
      "4       5                           Shrek Forever After    $752,600,867   \n",
      "..    ...                                           ...             ...   \n",
      "195   196                                   The Servant     $19,259,164   \n",
      "196   197                                Norwegian Wood     $19,115,721   \n",
      "197   198                               Head Over Heels     $18,876,082   \n",
      "198   199                                  13 Assassins     $18,689,058   \n",
      "199   200                    Green Zone 2010 Re-release     $18,495,045   \n",
      "\n",
      "         Domestic      %       Foreign    %.1  \n",
      "0    $415,004,880  38.9%  $651,964,823  61.1%  \n",
      "1    $334,191,110  32.6%  $691,276,000  67.4%  \n",
      "2    $295,983,305  30.3%  $680,553,613  69.7%  \n",
      "3    $292,576,195  35.3%  $535,682,500  64.7%  \n",
      "4    $238,736,787  31.7%  $513,864,080  68.3%  \n",
      "..            ...    ...           ...    ...  \n",
      "195             -      -   $19,259,164   100%  \n",
      "196       $13,000  <0.1%   $19,102,721  99.9%  \n",
      "197             -      -   $18,876,082   100%  \n",
      "198      $802,778   4.3%   $17,886,280  95.7%  \n",
      "199             -      -   $18,495,045   100%  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the website you want to scrape\n",
    "url = \"https://www.boxofficemojo.com/year/world/2010/\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data you want to extract\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Use Pandas to read the table into a DataFrame\n",
    "    df_bom_webscraping_2010 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_bom_webscraping_2010)\n",
    "\n",
    "    # Now you can work with the DataFrame as needed\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Release Group</th>\n",
       "      <th>Worldwide</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>%</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>%.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>$1,066,969,703</td>\n",
       "      <td>$415,004,880</td>\n",
       "      <td>38.9%</td>\n",
       "      <td>$651,964,823</td>\n",
       "      <td>61.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>$1,025,467,110</td>\n",
       "      <td>$334,191,110</td>\n",
       "      <td>32.6%</td>\n",
       "      <td>$691,276,000</td>\n",
       "      <td>67.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>$976,536,918</td>\n",
       "      <td>$295,983,305</td>\n",
       "      <td>30.3%</td>\n",
       "      <td>$680,553,613</td>\n",
       "      <td>69.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Inception</td>\n",
       "      <td>$828,258,695</td>\n",
       "      <td>$292,576,195</td>\n",
       "      <td>35.3%</td>\n",
       "      <td>$535,682,500</td>\n",
       "      <td>64.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Shrek Forever After</td>\n",
       "      <td>$752,600,867</td>\n",
       "      <td>$238,736,787</td>\n",
       "      <td>31.7%</td>\n",
       "      <td>$513,864,080</td>\n",
       "      <td>68.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>196</td>\n",
       "      <td>2018</td>\n",
       "      <td>$4,547,765</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>$4,547,765</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>197</td>\n",
       "      <td>IM HERO THE FINAL</td>\n",
       "      <td>$4,514,656</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>$4,514,656</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>198</td>\n",
       "      <td>Mari(dos)</td>\n",
       "      <td>$4,483,495</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>$4,483,495</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>199</td>\n",
       "      <td>Weekend Rebels</td>\n",
       "      <td>$4,477,262</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>$4,477,262</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>200</td>\n",
       "      <td>Maamannan</td>\n",
       "      <td>$4,463,992</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>$4,463,992</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank                                 Release Group       Worldwide  \\\n",
       "0        1                                   Toy Story 3  $1,066,969,703   \n",
       "1        2                           Alice in Wonderland  $1,025,467,110   \n",
       "2        3  Harry Potter and the Deathly Hallows: Part 1    $976,536,918   \n",
       "3        4                                     Inception    $828,258,695   \n",
       "4        5                           Shrek Forever After    $752,600,867   \n",
       "...    ...                                           ...             ...   \n",
       "2795   196                                          2018      $4,547,765   \n",
       "2796   197                             IM HERO THE FINAL      $4,514,656   \n",
       "2797   198                                     Mari(dos)      $4,483,495   \n",
       "2798   199                                Weekend Rebels      $4,477,262   \n",
       "2799   200                                     Maamannan      $4,463,992   \n",
       "\n",
       "          Domestic      %       Foreign    %.1  \n",
       "0     $415,004,880  38.9%  $651,964,823  61.1%  \n",
       "1     $334,191,110  32.6%  $691,276,000  67.4%  \n",
       "2     $295,983,305  30.3%  $680,553,613  69.7%  \n",
       "3     $292,576,195  35.3%  $535,682,500  64.7%  \n",
       "4     $238,736,787  31.7%  $513,864,080  68.3%  \n",
       "...            ...    ...           ...    ...  \n",
       "2795             -      -    $4,547,765   100%  \n",
       "2796             -      -    $4,514,656   100%  \n",
       "2797             -      -    $4,483,495   100%  \n",
       "2798             -      -    $4,477,262   100%  \n",
       "2799             -      -    $4,463,992   100%  \n",
       "\n",
       "[2800 rows x 7 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the combined data\n",
    "df_bom_webscraping = pd.DataFrame(columns=['Rank', 'Release Group', 'Worldwide', 'Domestic', '%', 'Foreign', '%.1'])\n",
    "\n",
    "# List of DataFrames\n",
    "dataframes = [df_bom_webscraping_2010, df_bom_webscraping_2011,\n",
    "              df_bom_webscraping_2012, df_bom_webscraping_2013, \n",
    "              df_bom_webscraping_2014, df_bom_webscraping_2015, \n",
    "              df_bom_webscraping_2016, df_bom_webscraping_2017, \n",
    "              df_bom_webscraping_2018, df_bom_webscraping_2019, \n",
    "              df_bom_webscraping_2020, df_bom_webscraping_2021, \n",
    "              df_bom_webscraping_2022, df_bom_webscraping_2023]\n",
    "\n",
    "# Loop through the list of DataFrames and concatenate them\n",
    "df_bom_webscraping = pd.concat([df for df in dataframes], ignore_index=True)\n",
    "\n",
    "\n",
    "df_bom_webscraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'df_boms_webscraping.csv'\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df_bom_webscraping.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2800 entries, 0 to 2799\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Rank           2800 non-null   int64 \n",
      " 1   Release Group  2800 non-null   object\n",
      " 2   Worldwide      2800 non-null   object\n",
      " 3   Domestic       2800 non-null   object\n",
      " 4   %              2800 non-null   object\n",
      " 5   Foreign        2800 non-null   object\n",
      " 6   %.1            2800 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 153.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bom_webscraping.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html5lib in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from html5lib) (1.15.0)\n",
      "Requirement already satisfied: webencodings in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from html5lib) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (4.14.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from selenium) (2.0.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6; extra == \"socks\" in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup; python_version < \"3.11\" in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.1.3)\n",
      "Requirement already satisfied: outcome in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (20.2.0)\n",
      "Requirement already satisfied: sniffio in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: selenium in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (4.14.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3[socks]<3,>=1.26 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from selenium) (2.0.7)\n",
      "Requirement already satisfied, skipping upgrade: trio-websocket~=0.9 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied, skipping upgrade: trio~=0.17 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2021.10.8 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied, skipping upgrade: pysocks!=1.5.7,<2.0,>=1.5.6; extra == \"socks\" in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: wsproto>=0.14 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: exceptiongroup; python_version < \"3.11\" in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: sortedcontainers in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: idna in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=20.1.0 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (20.2.0)\n",
      "Requirement already satisfied, skipping upgrade: outcome in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: sniffio in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: h11<1,>=0.9.0 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (4.0.1)\n",
      "Requirement already satisfied: packaging in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from webdriver_manager) (20.4)\n",
      "Requirement already satisfied: requests in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from webdriver_manager) (2.24.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from webdriver_manager) (1.0.0)\n",
      "Requirement already satisfied: six in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from packaging->webdriver_manager) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from packaging->webdriver_manager) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests->webdriver_manager) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests->webdriver_manager) (2023.7.22)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Installing collected packages: urllib3, chardet\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.7\n",
      "    Uninstalling urllib3-2.0.7:\n",
      "      Successfully uninstalled urllib3-2.0.7\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 5.2.0\n",
      "    Uninstalling chardet-5.2.0:\n",
      "      Successfully uninstalled chardet-5.2.0\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "selenium 4.14.0 requires urllib3[socks]<3,>=1.26, but you'll have urllib3 1.25.11 which is incompatible.\u001b[0m\n",
      "Successfully installed chardet-3.0.4 urllib3-1.25.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (4.14.0)\n",
      "Requirement already satisfied: webdriver_manager in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (4.0.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from selenium) (0.22.2)\n",
      "Collecting urllib3[socks]<3,>=1.26\n",
      "  Using cached urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: python-dotenv in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from webdriver_manager) (1.0.0)\n",
      "Requirement already satisfied: requests in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from webdriver_manager) (2.24.0)\n",
      "Requirement already satisfied: packaging in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from webdriver_manager) (20.4)\n",
      "Requirement already satisfied: exceptiongroup; python_version < \"3.11\" in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: sortedcontainers in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (20.2.0)\n",
      "Requirement already satisfied: sniffio in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: outcome in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6; extra == \"socks\" in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests->webdriver_manager) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from packaging->webdriver_manager) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from packaging->webdriver_manager) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.11\n",
      "    Uninstalling urllib3-1.25.11:\n",
      "      Successfully uninstalled urllib3-1.25.11\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "requests 2.24.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 2.0.7 which is incompatible.\n",
      "botocore 1.18.16 requires urllib3<1.26,>=1.20, but you'll have urllib3 2.0.7 which is incompatible.\u001b[0m\n",
      "Successfully installed urllib3-2.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: urllib3 in /Users/kariprimiano/anaconda3/envs/learn-env/lib/python3.8/site-packages (2.0.7)\n",
      "Collecting chardet\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: chardet\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 3.0.4\n",
      "    Uninstalling chardet-3.0.4:\n",
      "      Successfully uninstalled chardet-3.0.4\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "requests 2.24.0 requires chardet<4,>=3.0.2, but you'll have chardet 5.2.0 which is incompatible.\n",
      "requests 2.24.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 2.0.7 which is incompatible.\n",
      "aiohttp 3.6.2 requires chardet<4.0,>=2.0, but you'll have chardet 5.2.0 which is incompatible.\u001b[0m\n",
      "Successfully installed chardet-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade urllib3 chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'capabilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/selenium/webdriver/common/driver_finder.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(service, options)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeleniumManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/selenium/webdriver/common/selenium_manager.py\u001b[0m in \u001b[0;36mdriver_location\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mbrowser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'capabilities'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-184855828a41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Initialize the Chrome WebDriver using the manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChromeDriverManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Specify the URL of the webpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mDesiredCapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHROME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;34m\"goog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDriverFinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/selenium/webdriver/common/driver_finder.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(service, options)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeleniumManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Unable to obtain driver for {options.capabilities['browserName']} using Selenium Manager.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchDriverException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'capabilities'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize the Chrome WebDriver using the manager\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "# Specify the URL of the webpage\n",
    "url = \"https://www.the-numbers.com/movie/budgets/all\"\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(url)\n",
    "\n",
    "# Get the page source after waiting for some time (adjust the delay as needed)\n",
    "time.sleep(5)  # Wait for 5 seconds (you can adjust this)\n",
    "\n",
    "# Get the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table = soup.find('table')\n",
    "\n",
    "# Read the table into a DataFrame using Pandas\n",
    "df = pd.read_html(str(table))[0]  # Adjust if there are multiple tables on the page\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie</th>\n",
       "      <th>production_budget</th>\n",
       "      <th>domestic_gross</th>\n",
       "      <th>worldwide_gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dec 18, 2009</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>$425,000,000</td>\n",
       "      <td>$760,507,625</td>\n",
       "      <td>$2,776,345,279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>May 20, 2011</td>\n",
       "      <td>Pirates of the Caribbean: On Stranger Tides</td>\n",
       "      <td>$410,600,000</td>\n",
       "      <td>$241,063,875</td>\n",
       "      <td>$1,045,663,875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jun 7, 2019</td>\n",
       "      <td>Dark Phoenix</td>\n",
       "      <td>$350,000,000</td>\n",
       "      <td>$42,762,350</td>\n",
       "      <td>$149,762,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>May 1, 2015</td>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>$330,600,000</td>\n",
       "      <td>$459,005,868</td>\n",
       "      <td>$1,403,013,963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Dec 15, 2017</td>\n",
       "      <td>Star Wars Ep. VIII: The Last Jedi</td>\n",
       "      <td>$317,000,000</td>\n",
       "      <td>$620,181,382</td>\n",
       "      <td>$1,316,721,747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5777</th>\n",
       "      <td>78</td>\n",
       "      <td>Dec 31, 2018</td>\n",
       "      <td>Red 11</td>\n",
       "      <td>$7,000</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5778</th>\n",
       "      <td>79</td>\n",
       "      <td>Apr 2, 1999</td>\n",
       "      <td>Following</td>\n",
       "      <td>$6,000</td>\n",
       "      <td>$48,482</td>\n",
       "      <td>$240,495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>80</td>\n",
       "      <td>Jul 13, 2005</td>\n",
       "      <td>Return to the Land of Wonders</td>\n",
       "      <td>$5,000</td>\n",
       "      <td>$1,338</td>\n",
       "      <td>$1,338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5780</th>\n",
       "      <td>81</td>\n",
       "      <td>Sep 29, 2015</td>\n",
       "      <td>A Plague So Pleasant</td>\n",
       "      <td>$1,400</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>82</td>\n",
       "      <td>Aug 5, 2005</td>\n",
       "      <td>My Date With Drew</td>\n",
       "      <td>$1,100</td>\n",
       "      <td>$181,041</td>\n",
       "      <td>$181,041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5782 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  release_date                                        movie  \\\n",
       "0      1  Dec 18, 2009                                       Avatar   \n",
       "1      2  May 20, 2011  Pirates of the Caribbean: On Stranger Tides   \n",
       "2      3   Jun 7, 2019                                 Dark Phoenix   \n",
       "3      4   May 1, 2015                      Avengers: Age of Ultron   \n",
       "4      5  Dec 15, 2017            Star Wars Ep. VIII: The Last Jedi   \n",
       "...   ..           ...                                          ...   \n",
       "5777  78  Dec 31, 2018                                       Red 11   \n",
       "5778  79   Apr 2, 1999                                    Following   \n",
       "5779  80  Jul 13, 2005                Return to the Land of Wonders   \n",
       "5780  81  Sep 29, 2015                         A Plague So Pleasant   \n",
       "5781  82   Aug 5, 2005                            My Date With Drew   \n",
       "\n",
       "     production_budget domestic_gross worldwide_gross  \n",
       "0         $425,000,000   $760,507,625  $2,776,345,279  \n",
       "1         $410,600,000   $241,063,875  $1,045,663,875  \n",
       "2         $350,000,000    $42,762,350    $149,762,350  \n",
       "3         $330,600,000   $459,005,868  $1,403,013,963  \n",
       "4         $317,000,000   $620,181,382  $1,316,721,747  \n",
       "...                ...            ...             ...  \n",
       "5777            $7,000             $0              $0  \n",
       "5778            $6,000        $48,482        $240,495  \n",
       "5779            $5,000         $1,338          $1,338  \n",
       "5780            $1,400             $0              $0  \n",
       "5781            $1,100       $181,041        $181,041  \n",
       "\n",
       "[5782 rows x 6 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_budgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie</th>\n",
       "      <th>production_budget</th>\n",
       "      <th>domestic_gross</th>\n",
       "      <th>worldwide_gross</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>95</td>\n",
       "      <td>Dec 31, 2020</td>\n",
       "      <td>Moonfall</td>\n",
       "      <td>$150,000,000</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>36</td>\n",
       "      <td>Feb 21, 2020</td>\n",
       "      <td>Call of the Wild</td>\n",
       "      <td>$82,000,000</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>6</td>\n",
       "      <td>Dec 31, 2020</td>\n",
       "      <td>Hannibal the Conqueror</td>\n",
       "      <td>$50,000,000</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>30</td>\n",
       "      <td>Sep 30, 2019</td>\n",
       "      <td>Unhinged</td>\n",
       "      <td>$29,000,000</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>71</td>\n",
       "      <td>Aug 30, 2019</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>$75,000,000</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5606</th>\n",
       "      <td>7</td>\n",
       "      <td>Nov 19, 1925</td>\n",
       "      <td>The Big Parade</td>\n",
       "      <td>$245,000</td>\n",
       "      <td>$11,000,000</td>\n",
       "      <td>$22,000,000</td>\n",
       "      <td>1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5683</th>\n",
       "      <td>84</td>\n",
       "      <td>Sep 17, 1920</td>\n",
       "      <td>Over the Hill to the Poorhouse</td>\n",
       "      <td>$100,000</td>\n",
       "      <td>$3,000,000</td>\n",
       "      <td>$3,000,000</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>15</td>\n",
       "      <td>Dec 24, 1916</td>\n",
       "      <td>20,000 Leagues Under the Sea</td>\n",
       "      <td>$200,000</td>\n",
       "      <td>$8,000,000</td>\n",
       "      <td>$8,000,000</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>24</td>\n",
       "      <td>Sep 5, 1916</td>\n",
       "      <td>Intolerance</td>\n",
       "      <td>$385,907</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>78</td>\n",
       "      <td>Feb 8, 1915</td>\n",
       "      <td>The Birth of a Nation</td>\n",
       "      <td>$110,000</td>\n",
       "      <td>$10,000,000</td>\n",
       "      <td>$11,000,000</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5782 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  release_date                           movie production_budget  \\\n",
       "194   95  Dec 31, 2020                        Moonfall      $150,000,000   \n",
       "535   36  Feb 21, 2020                Call of the Wild       $82,000,000   \n",
       "1205   6  Dec 31, 2020          Hannibal the Conqueror       $50,000,000   \n",
       "2029  30  Sep 30, 2019                        Unhinged       $29,000,000   \n",
       "670   71  Aug 30, 2019                       PLAYMOBIL       $75,000,000   \n",
       "...   ..           ...                             ...               ...   \n",
       "5606   7  Nov 19, 1925                  The Big Parade          $245,000   \n",
       "5683  84  Sep 17, 1920  Over the Hill to the Poorhouse          $100,000   \n",
       "5614  15  Dec 24, 1916    20,000 Leagues Under the Sea          $200,000   \n",
       "5523  24   Sep 5, 1916                     Intolerance          $385,907   \n",
       "5677  78   Feb 8, 1915           The Birth of a Nation          $110,000   \n",
       "\n",
       "     domestic_gross worldwide_gross  year  \n",
       "194              $0              $0  2020  \n",
       "535              $0              $0  2020  \n",
       "1205             $0              $0  2020  \n",
       "2029             $0              $0  2019  \n",
       "670              $0              $0  2019  \n",
       "...             ...             ...   ...  \n",
       "5606    $11,000,000     $22,000,000  1925  \n",
       "5683     $3,000,000      $3,000,000  1920  \n",
       "5614     $8,000,000      $8,000,000  1916  \n",
       "5523             $0              $0  1916  \n",
       "5677    $10,000,000     $11,000,000  1915  \n",
       "\n",
       "[5782 rows x 7 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_budgets['year'] = df_budgets['release_date'].str[-4:]\n",
    "\n",
    "sorted_df_budgets = df_budgets.sort_values(by=['year'], ascending=False)\n",
    "\n",
    "sorted_df_budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Released                                 Title      Genre  \\\n",
      "0           1      2015  Star Wars Ep. VII: The Force Awakens  Adventure   \n",
      "1           2      2019                     Avengers: Endgame     Action   \n",
      "2           3      2021               Spider-Man: No Way Home     Action   \n",
      "3           4      2009                                Avatar     Action   \n",
      "4           5      2022                     Top Gun: Maverick     Action   \n",
      "\n",
      "                         Source       ProductionMethod          CreativeType  \\\n",
      "0           Original Screenplay  Animation/Live Action       Science Fiction   \n",
      "1  Based on Comic/Graphic Novel  Animation/Live Action            Super Hero   \n",
      "2  Based on Comic/Graphic Novel            Live Action            Super Hero   \n",
      "3           Original Screenplay  Animation/Live Action       Science Fiction   \n",
      "4           Original Screenplay            Live Action  Contemporary Fiction   \n",
      "\n",
      "  ProductionBudget DomesticBox Office Infl. Adj. Dom.Box Office  \n",
      "0     $306,000,000       $936,662,225            $1,163,816,804  \n",
      "1     $400,000,000       $858,373,000              $986,754,117  \n",
      "2     $200,000,000       $814,115,070              $821,277,378  \n",
      "3     $237,000,000       $785,221,649            $1,064,124,576  \n",
      "4     $170,000,000       $718,732,821              $718,732,821  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "# Define the URL of the webpage to scrape\n",
    "url = \"https://www.the-numbers.com/movies/report/All/All/All/All/All/All/All/All/All/None/None/None/None/None/None/None/None/None/None?view-order-by=domestic-box-office&show-release-year=On&view-order-direction=desc&show-production-budget=On&show-domestic-box-office=On&show-inflation-adjusted-domestic-box-office=On&show-genre=On&show-source=On&show-production-method=On&show-creative-type=On\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the table element that contains the data\n",
    "    table = soup.find(\"table\")\n",
    "\n",
    "    # Use Pandas to read the HTML table into a DataFrame\n",
    "    df_tn1 = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Optionally, clean and preprocess the data as needed\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df_tn1.head())\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0   ReleaseDate                             Movie  \\\n",
      "0           6401   Dec 1, 2015                       Dutch Kills   \n",
      "1           6402   Aug 1, 1991                           Slacker   \n",
      "2           6403       Unknown                         Dry Spell   \n",
      "3           6404  Jan 11, 2002                      Steel Spirit   \n",
      "4           6405   Aug 9, 2019                          Socrates   \n",
      "...          ...           ...                               ...   \n",
      "6429          96   Sep 4, 2020                             Mulan   \n",
      "6430          97   Jul 2, 2021                  The Tomorrow War   \n",
      "6431          98  Jul 13, 2022                      The Gray Man   \n",
      "6432          99  Jun 29, 2011    Transformers: Dark of the Moon   \n",
      "6433         100   Jun 6, 2023  Transformers: Rise of the Beasts   \n",
      "\n",
      "     ProductionBudget DomesticGross  WorldwideGross  \n",
      "0             $25,000            $0              $0  \n",
      "1             $23,000    $1,227,508      $1,227,508  \n",
      "2             $22,000            $0              $0  \n",
      "3             $20,000        $1,860          $1,860  \n",
      "4             $20,000            $0            $849  \n",
      "...               ...           ...             ...  \n",
      "6429     $200,000,000            $0     $69,973,540  \n",
      "6430     $200,000,000            $0     $19,220,000  \n",
      "6431     $200,000,000            $0        $451,178  \n",
      "6432     $195,000,000  $352,390,543  $1,123,794,079  \n",
      "6433     $195,000,000  $157,066,392    $437,806,355  \n",
      "\n",
      "[6434 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Define a function to scrape data from a single URL\n",
    "def scrape_data(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "        df = pd.read_html(str(table))[0]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.the-numbers.com/movie/budgets/all/6401\",\n",
    "    \"https://www.the-numbers.com/movie/budgets/all/6301\",\n",
    "    'https://www.the-numbers.com/movie/budgets/all/6201',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/6101',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/6001',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/5901',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/5801',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/5701',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/5601',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/5501',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/5401',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/5301',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/5201',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/5101',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/5001',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/4901',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/4801',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/4701',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/4601',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/4501',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/4401',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/4301',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/4201',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/4101',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/4001',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/3901',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/3801',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/3701',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/3601',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/3501',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/3401',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/3301',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/3201',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/3101',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/3001',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/2901',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/2801',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/2701',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/2601',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/2501',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/2401',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/2301',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/2201',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/2101',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/2001',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/1901',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/1801',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/1701',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/1601',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/1501',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/1401',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/1301',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/1201',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/1101',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/1001',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/901',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/801',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/701',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/601',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/501',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/401',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/301',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/201',\n",
    "    'https://www.the-numbers.com/movie/budgets/all/101',\n",
    "    'https://www.the-numbers.com/movie/budgets/all'\n",
    "    \n",
    "]\n",
    "\n",
    "# Create a ThreadPoolExecutor to execute scraping tasks concurrently\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Submit scraping tasks for each URL\n",
    "    results = [executor.submit(scrape_data, url) for url in urls]\n",
    "\n",
    "# Collect the results (DataFrames) from the completed tasks\n",
    "dataframes = [result.result() for result in results if result.result() is not None]\n",
    "\n",
    "# Concatenate the DataFrames into a single DataFrame\n",
    "df_tn = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display or further process the combined DataFrame\n",
    "print(df_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0        Dec 1, 2015\n",
       "1        Aug 1, 1991\n",
       "2            Unknown\n",
       "3       Jan 11, 2002\n",
       "4        Aug 9, 2019\n",
       "            ...     \n",
       "6429     Sep 4, 2020\n",
       "6430     Jul 2, 2021\n",
       "6431    Jul 13, 2022\n",
       "6432    Jun 29, 2011\n",
       "6433     Jun 6, 2023\n",
       "Name: ReleaseDate, Length: 6434, dtype: object>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tn['ReleaseDate'].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tn['Year'] = df_tn['ReleaseDate'].str[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015    345\n",
       "2010    261\n",
       "2016    261\n",
       "2012    257\n",
       "2014    255\n",
       "2011    248\n",
       "2013    232\n",
       "2018    200\n",
       "2017    189\n",
       "2019    175\n",
       "2021     93\n",
       "2020     78\n",
       "2022     69\n",
       "2023     55\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tn = df_tn.loc[(df_tn['Year'] >= '2010') & (df_tn['Year'] <= '2023')]\n",
    "df_tn['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2718 entries, 0 to 6433\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Unnamed: 0        2718 non-null   int64 \n",
      " 1   ReleaseDate       2718 non-null   object\n",
      " 2   Movie             2718 non-null   object\n",
      " 3   ProductionBudget  2718 non-null   object\n",
      " 4   DomesticGross     2718 non-null   object\n",
      " 5   WorldwideGross    2718 non-null   object\n",
      " 6   Year              2718 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 169.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_tn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'tn_budgets.csv'\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df_tn.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
